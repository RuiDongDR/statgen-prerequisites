{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# Hidden Markov Model\n",
    "\n",
    "A Hidden Markov Model (HMM) is a statistical model that describes a system where we observe a sequence of outputs, but the underlying states that generate these outputs are hidden from us - we model both the **transitions between hidden states** and the **probabilities of observing outputs from each state**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graphical",
   "metadata": {},
   "source": [
    "# Graphical Summary\n",
    "\n",
    "![Fig](./graphical_summary/slides/HMM_placeholder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "key_formula",
   "metadata": {},
   "source": [
    "# Key Formula\n",
    "\n",
    "An HMM is defined by three key components:\n",
    "\n",
    "**1. State Transition Matrix** $\\mathbf{A}$:\n",
    "\n",
    "$$\n",
    "a_{ij} = P(z_t = j \\mid z_{t-1} = i)\n",
    "$$\n",
    "\n",
    "where $z_t$ is the hidden state at time/position $t$.\n",
    "\n",
    "**2. Emission Probability** $\\mathbf{B}$:\n",
    "\n",
    "$$\n",
    "b_j(x) = P(x_t = x \\mid z_t = j)\n",
    "$$\n",
    "\n",
    "where $x_t$ is the observed value at time/position $t$.\n",
    "\n",
    "**3. Initial State Distribution** $\\boldsymbol{\\pi}$:\n",
    "\n",
    "$$\n",
    "\\pi_i = P(z_1 = i)\n",
    "$$\n",
    "\n",
    "The joint probability of observing a sequence $\\mathbf{x} = (x_1, x_2, \\ldots, x_T)$ and hidden states $\\mathbf{z} = (z_1, z_2, \\ldots, z_T)$ is:\n",
    "\n",
    "$$\n",
    "P(\\mathbf{x}, \\mathbf{z}) = \\pi_{z_1} \\prod_{t=2}^{T} a_{z_{t-1},z_t} \\prod_{t=1}^{T} b_{z_t}(x_t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical",
   "metadata": {},
   "source": [
    "# Technical Details\n",
    "\n",
    "## Core Concepts\n",
    "\n",
    "Hidden Markov Models extend simple Markov chains by adding an observation layer. While we cannot directly observe the states, we can observe outputs that depend on these states. This makes HMMs powerful for modeling sequential data where the underlying process is not directly observable.\n",
    "\n",
    "**Key assumptions:**\n",
    "1. **Markov property**: The current state depends only on the previous state, not the entire history: $P(z_t \\mid z_1, \\ldots, z_{t-1}) = P(z_t \\mid z_{t-1})$\n",
    "2. **Observation independence**: Given the state, the observation is independent of all other states and observations: $P(x_t \\mid z_1, \\ldots, z_T, x_1, \\ldots, x_{t-1}) = P(x_t \\mid z_t)$\n",
    "3. **Stationary**: Transition and emission probabilities don't change over time (though this can be relaxed)\n",
    "\n",
    "## Three Fundamental Problems\n",
    "\n",
    "### 1. Evaluation Problem (Forward Algorithm)\n",
    "\n",
    "**Question**: Given an HMM model $\\lambda = (\\mathbf{A}, \\mathbf{B}, \\boldsymbol{\\pi})$ and observation sequence $\\mathbf{x}$, what is $P(\\mathbf{x} \\mid \\lambda)$?\n",
    "\n",
    "The forward algorithm computes this efficiently using dynamic programming:\n",
    "\n",
    "$$\n",
    "\\alpha_t(i) = P(x_1, \\ldots, x_t, z_t = i \\mid \\lambda)\n",
    "$$\n",
    "\n",
    "**Recursion**:\n",
    "- Initialization: $\\alpha_1(i) = \\pi_i b_i(x_1)$\n",
    "- Recursion: $\\alpha_{t+1}(j) = b_j(x_{t+1}) \\sum_{i=1}^{N} \\alpha_t(i) a_{ij}$\n",
    "- Termination: $P(\\mathbf{x} \\mid \\lambda) = \\sum_{i=1}^{N} \\alpha_T(i)$\n",
    "\n",
    "### 2. Decoding Problem (Viterbi Algorithm)\n",
    "\n",
    "**Question**: Given observations $\\mathbf{x}$, what is the most likely sequence of hidden states?\n",
    "\n",
    "The Viterbi algorithm finds the optimal state path:\n",
    "\n",
    "$$\n",
    "\\delta_t(i) = \\max_{z_1, \\ldots, z_{t-1}} P(z_1, \\ldots, z_{t-1}, z_t = i, x_1, \\ldots, x_t \\mid \\lambda)\n",
    "$$\n",
    "\n",
    "**Recursion**:\n",
    "- Initialization: $\\delta_1(i) = \\pi_i b_i(x_1)$\n",
    "- Recursion: $\\delta_{t+1}(j) = b_j(x_{t+1}) \\max_i [\\delta_t(i) a_{ij}]$\n",
    "- Backtracking: Trace back from $\\arg\\max_i \\delta_T(i)$ to recover the optimal path\n",
    "\n",
    "### 3. Learning Problem (Baum-Welch Algorithm)\n",
    "\n",
    "**Question**: Given observations $\\mathbf{x}$, how do we estimate the parameters $\\lambda = (\\mathbf{A}, \\mathbf{B}, \\boldsymbol{\\pi})$?\n",
    "\n",
    "The Baum-Welch algorithm (an EM algorithm) iteratively updates parameters:\n",
    "\n",
    "**E-step**: Compute posterior probabilities using forward-backward algorithm\n",
    "**M-step**: Update parameters based on expected counts\n",
    "\n",
    "## Applications in Statistical Genetics\n",
    "\n",
    "HMMs are widely used in genetics because DNA sequences naturally exhibit:\n",
    "1. **Sequential structure**: Neighboring loci are correlated due to linkage disequilibrium\n",
    "2. **Hidden states**: Ancestry, haplotype structure, or functional states are not directly observed\n",
    "3. **Noisy observations**: Genotyping errors, low-coverage sequencing\n",
    "\n",
    "**Common applications**:\n",
    "- **Local ancestry inference**: Hidden states represent ancestral populations\n",
    "- **Genotype imputation**: Hidden states are true haplotypes, observations are typed markers\n",
    "- **Copy number variation detection**: Hidden states indicate copy number, observations are read depths\n",
    "- **Chromatin state annotation**: Hidden states are functional states (promoter, enhancer, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related",
   "metadata": {},
   "source": [
    "# Related Topics\n",
    "\n",
    "- [Linkage Disequilibrium](https://statfungen.github.io/statgen-prerequisites/linkage_disequilibrium.html)\n",
    "- [Hardy-Weinberg Equilibrium](https://statfungen.github.io/statgen-prerequisites/Hardy_Weinberg_equilibrium.html)\n",
    "- [Bayesian Mixture Model](https://statfungen.github.io/statgen-prerequisites/Bayesian_mixture_model.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example_intro",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example1_intro",
   "metadata": {},
   "source": [
    "## Example 1: Basic HMM - Casino Dice\n",
    "\n",
    "Let's start with a classic example that illustrates the core concepts of HMMs. Imagine a casino that sometimes switches between a fair die and a loaded die. We can observe the outcomes (die rolls), but we cannot see which die is being used. This is a perfect scenario for an HMM.\n",
    "\n",
    "**Hidden states**: Which die is being used (Fair or Loaded)\n",
    "**Observations**: The numbers we see on the die (1-6)\n",
    "**Goal**: Infer which die was likely used for each roll, given only the sequence of observed outcomes\n",
    "\n",
    "This example parallels many genetics problems where we have:\n",
    "- Hidden states: ancestry, true genotypes, functional states\n",
    "- Observations: genotype data with noise/errors\n",
    "- Goal: Infer the hidden states from observed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example1_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm(list=ls())\n",
    "set.seed(123)\n",
    "\n",
    "# Define the HMM parameters for the casino problem\n",
    "# Hidden states: 1 = Fair die, 2 = Loaded die\n",
    "\n",
    "# Initial state probabilities\n",
    "# Start with 95% probability of fair die\n",
    "pi <- c(0.95, 0.05)\n",
    "names(pi) <- c(\"Fair\", \"Loaded\")\n",
    "\n",
    "# State transition matrix\n",
    "# Rows = current state, Columns = next state\n",
    "# Most of the time, stay in current state (diagonal is high)\n",
    "A <- matrix(c(\n",
    "  0.95, 0.05,   # From Fair: 95% stay Fair, 5% switch to Loaded\n",
    "  0.10, 0.90    # From Loaded: 10% switch to Fair, 90% stay Loaded\n",
    "), nrow = 2, byrow = TRUE)\n",
    "rownames(A) <- colnames(A) <- c(\"Fair\", \"Loaded\")\n",
    "\n",
    "# Emission probabilities\n",
    "# Rows = states, Columns = possible observations (1-6)\n",
    "# Fair die: uniform probability 1/6 for each outcome\n",
    "# Loaded die: biased toward 6\n",
    "B <- matrix(c(\n",
    "  1/6, 1/6, 1/6, 1/6, 1/6, 1/6,      # Fair die\n",
    "  1/10, 1/10, 1/10, 1/10, 1/10, 1/2  # Loaded die (50% chance of 6)\n",
    "), nrow = 2, byrow = TRUE)\n",
    "rownames(B) <- c(\"Fair\", \"Loaded\")\n",
    "colnames(B) <- paste0(\"Die=\", 1:6)\n",
    "\n",
    "cat(\"HMM Parameters:\\n\")\n",
    "cat(\"\\nInitial state probabilities:\\n\")\n",
    "print(pi)\n",
    "cat(\"\\nState transition matrix A:\\n\")\n",
    "print(A)\n",
    "cat(\"\\nEmission probabilities B:\\n\")\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example1_simulate",
   "metadata": {},
   "source": [
    "### Simulate Data from the HMM\n",
    "\n",
    "Let's generate a sequence of observations by simulating the hidden state sequence first, then generating observations based on those states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example1_sim_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to simulate from HMM\n",
    "simulate_hmm <- function(pi, A, B, T) {\n",
    "  n_states <- length(pi)\n",
    "  n_obs <- ncol(B)\n",
    "  \n",
    "  # Storage\n",
    "  states <- integer(T)\n",
    "  observations <- integer(T)\n",
    "  \n",
    "  # Initial state\n",
    "  states[1] <- sample(1:n_states, size = 1, prob = pi)\n",
    "  observations[1] <- sample(1:n_obs, size = 1, prob = B[states[1], ])\n",
    "  \n",
    "  # Generate sequence\n",
    "  for (t in 2:T) {\n",
    "    # Sample next state based on current state\n",
    "    states[t] <- sample(1:n_states, size = 1, prob = A[states[t-1], ])\n",
    "    # Sample observation from current state\n",
    "    observations[t] <- sample(1:n_obs, size = 1, prob = B[states[t], ])\n",
    "  }\n",
    "  \n",
    "  return(list(states = states, observations = observations))\n",
    "}\n",
    "\n",
    "# Simulate sequence of length 300\n",
    "T <- 300\n",
    "sim_data <- simulate_hmm(pi, A, B, T)\n",
    "true_states <- sim_data$states\n",
    "observations <- sim_data$observations\n",
    "\n",
    "# Convert states to names for clarity\n",
    "state_names <- c(\"Fair\", \"Loaded\")\n",
    "\n",
    "cat(\"\\nSimulated Data (first 50 positions):\\n\")\n",
    "cat(\"Observations: \", observations[1:50], \"\\n\")\n",
    "cat(\"True states:  \", state_names[true_states[1:50]], \"\\n\")\n",
    "\n",
    "# Summary statistics\n",
    "cat(\"\\nSummary Statistics:\\n\")\n",
    "cat(\"Total time points:\", T, \"\\n\")\n",
    "cat(\"Fair die used:\", sum(true_states == 1), \"times (\", \n",
    "    round(100*sum(true_states == 1)/T, 1), \"%)\\n\")\n",
    "cat(\"Loaded die used:\", sum(true_states == 2), \"times (\", \n",
    "    round(100*sum(true_states == 2)/T, 1), \"%)\\n\")\n",
    "cat(\"Number of state switches:\", sum(diff(true_states) != 0), \"\\n\")\n",
    "cat(\"\\nObserved frequency of 6's:\", sum(observations == 6), \"out of\", T, \n",
    "    \"(\", round(100*sum(observations == 6)/T, 1), \"%)\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example1_visualize",
   "metadata": {},
   "source": [
    "### Visualize the Simulated Data\n",
    "\n",
    "Let's plot the observations and the true hidden states to see the pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example1_plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot observations with true states colored\n",
    "par(mfrow = c(2, 1), mar = c(4, 4, 3, 1))\n",
    "\n",
    "# Plot 1: Observations colored by true state\n",
    "plot(1:T, observations, pch = 16, cex = 0.8,\n",
    "     col = c(\"steelblue\", \"red\")[true_states],\n",
    "     xlab = \"Time\", ylab = \"Die Roll\",\n",
    "     main = \"Observed Die Rolls (colored by true hidden state)\",\n",
    "     ylim = c(0.5, 6.5))\n",
    "legend(\"topleft\", legend = c(\"Fair die\", \"Loaded die\"),\n",
    "       col = c(\"steelblue\", \"red\"), pch = 16, cex = 0.8)\n",
    "\n",
    "# Plot 2: True hidden states over time\n",
    "plot(1:T, true_states, type = \"s\", lwd = 2, col = \"darkgreen\",\n",
    "     xlab = \"Time\", ylab = \"State\",\n",
    "     main = \"True Hidden States Over Time\",\n",
    "     ylim = c(0.5, 2.5), yaxt = \"n\")\n",
    "axis(2, at = 1:2, labels = c(\"Fair\", \"Loaded\"))\n",
    "\n",
    "par(mfrow = c(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example1_forward",
   "metadata": {},
   "source": [
    "### Inference: Forward Algorithm\n",
    "\n",
    "Now let's implement the forward algorithm to compute the probability of the observed sequence. This algorithm efficiently computes $P(\\mathbf{x} \\mid \\lambda)$ using dynamic programming.\n",
    "\n",
    "**Key insight**: At each time step, we maintain the probability of seeing the observations up to that point and being in each possible state. This lets us avoid enumerating all possible state sequences (which would be exponential in the length)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example1_forward_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward algorithm implementation\n",
    "forward_algorithm <- function(observations, pi, A, B) {\n",
    "  T <- length(observations)\n",
    "  n_states <- length(pi)\n",
    "  \n",
    "  # Initialize forward variables (log scale for numerical stability)\n",
    "  log_alpha <- matrix(0, nrow = T, ncol = n_states)\n",
    "  \n",
    "  # Initialization: t=1\n",
    "  log_alpha[1, ] <- log(pi) + log(B[, observations[1]])\n",
    "  \n",
    "  # Recursion: t=2 to T\n",
    "  for (t in 2:T) {\n",
    "    for (j in 1:n_states) {\n",
    "      # Sum over all possible previous states\n",
    "      log_alpha[t, j] <- log(sum(exp(log_alpha[t-1, ] + log(A[, j])))) + \n",
    "                         log(B[j, observations[t]])\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # Termination: log P(observations | model)\n",
    "  log_prob <- log(sum(exp(log_alpha[T, ])))\n",
    "  \n",
    "  return(list(log_alpha = log_alpha, log_prob = log_prob))\n",
    "}\n",
    "\n",
    "# Run forward algorithm\n",
    "forward_result <- forward_algorithm(observations, pi, A, B)\n",
    "\n",
    "cat(\"\\nForward Algorithm Results:\\n\")\n",
    "cat(\"Log probability of observed sequence: \", forward_result$log_prob, \"\\n\")\n",
    "cat(\"Probability of observed sequence: \", exp(forward_result$log_prob), \"\\n\")\n",
    "\n",
    "# Show forward probabilities at a few time points\n",
    "cat(\"\\nForward probabilities at selected time points:\\n\")\n",
    "selected_times <- c(1, 50, 100, 150, 200, 250, 300)\n",
    "for (t in selected_times) {\n",
    "  alpha_t <- exp(forward_result$log_alpha[t, ])\n",
    "  alpha_t <- alpha_t / sum(alpha_t)  # Normalize for interpretation\n",
    "  cat(sprintf(\"Time %3d: P(Fair|obs[1:%d]) = %.3f, P(Loaded|obs[1:%d]) = %.3f\\n\", \n",
    "              t, t, alpha_t[1], t, alpha_t[2]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example1_viterbi",
   "metadata": {},
   "source": [
    "### Inference: Viterbi Algorithm\n",
    "\n",
    "The Viterbi algorithm finds the most likely sequence of hidden states given the observations. Instead of summing over all paths (like forward algorithm), it finds the single best path.\n",
    "\n",
    "**Key difference from forward algorithm**: Use max instead of sum when combining paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example1_viterbi_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi algorithm implementation\n",
    "viterbi_algorithm <- function(observations, pi, A, B) {\n",
    "  T <- length(observations)\n",
    "  n_states <- length(pi)\n",
    "  \n",
    "  # Initialize\n",
    "  log_delta <- matrix(0, nrow = T, ncol = n_states)\n",
    "  psi <- matrix(0, nrow = T, ncol = n_states)\n",
    "  \n",
    "  # Initialization: t=1\n",
    "  log_delta[1, ] <- log(pi) + log(B[, observations[1]])\n",
    "  \n",
    "  # Recursion: t=2 to T\n",
    "  for (t in 2:T) {\n",
    "    for (j in 1:n_states) {\n",
    "      # Find the most likely previous state\n",
    "      temp <- log_delta[t-1, ] + log(A[, j])\n",
    "      psi[t, j] <- which.max(temp)\n",
    "      log_delta[t, j] <- max(temp) + log(B[j, observations[t]])\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # Termination: find best final state\n",
    "  best_path <- integer(T)\n",
    "  best_path[T] <- which.max(log_delta[T, ])\n",
    "  \n",
    "  # Backtracking: trace back the best path\n",
    "  for (t in (T-1):1) {\n",
    "    best_path[t] <- psi[t+1, best_path[t+1]]\n",
    "  }\n",
    "  \n",
    "  log_prob <- max(log_delta[T, ])\n",
    "  \n",
    "  return(list(best_path = best_path, log_prob = log_prob))\n",
    "}\n",
    "\n",
    "# Run Viterbi algorithm\n",
    "viterbi_result <- viterbi_algorithm(observations, pi, A, B)\n",
    "predicted_states <- viterbi_result$best_path\n",
    "\n",
    "cat(\"\\nViterbi Algorithm Results:\\n\")\n",
    "cat(\"Log probability of best path: \", viterbi_result$log_prob, \"\\n\")\n",
    "\n",
    "# Compare predicted vs true states\n",
    "accuracy <- sum(predicted_states == true_states) / T\n",
    "cat(\"\\nAccuracy: \", round(100*accuracy, 2), \"%\\n\")\n",
    "\n",
    "# Confusion matrix\n",
    "confusion <- table(True = state_names[true_states], \n",
    "                   Predicted = state_names[predicted_states])\n",
    "cat(\"\\nConfusion Matrix:\\n\")\n",
    "print(confusion)\n",
    "\n",
    "# Show first 50 predictions\n",
    "cat(\"\\nFirst 50 positions:\\n\")\n",
    "cat(\"Observations: \", observations[1:50], \"\\n\")\n",
    "cat(\"True states:  \", state_names[true_states[1:50]], \"\\n\")\n",
    "cat(\"Predicted:    \", state_names[predicted_states[1:50]], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example1_compare",
   "metadata": {},
   "source": [
    "### Visualize Inference Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example1_compare_plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparing true vs predicted states\n",
    "par(mfrow = c(3, 1), mar = c(3, 4, 2, 1))\n",
    "\n",
    "# Plot 1: Observations\n",
    "plot(1:T, observations, pch = 16, cex = 0.6, col = \"gray40\",\n",
    "     xlab = \"\", ylab = \"Die Roll\",\n",
    "     main = \"Observed Die Rolls\",\n",
    "     ylim = c(0.5, 6.5))\n",
    "\n",
    "# Plot 2: True states\n",
    "plot(1:T, true_states, type = \"s\", lwd = 2, col = \"darkgreen\",\n",
    "     xlab = \"\", ylab = \"State\",\n",
    "     main = \"True Hidden States\",\n",
    "     ylim = c(0.5, 2.5), yaxt = \"n\")\n",
    "axis(2, at = 1:2, labels = c(\"Fair\", \"Loaded\"))\n",
    "\n",
    "# Plot 3: Predicted states with errors highlighted\n",
    "plot(1:T, predicted_states, type = \"s\", lwd = 2, col = \"steelblue\",\n",
    "     xlab = \"Time\", ylab = \"State\",\n",
    "     main = \"Predicted States (Viterbi)\",\n",
    "     ylim = c(0.5, 2.5), yaxt = \"n\")\n",
    "axis(2, at = 1:2, labels = c(\"Fair\", \"Loaded\"))\n",
    "\n",
    "# Highlight errors\n",
    "errors <- which(predicted_states != true_states)\n",
    "if (length(errors) > 0) {\n",
    "  points(errors, predicted_states[errors], col = \"red\", pch = 16, cex = 0.8)\n",
    "}\n",
    "\n",
    "par(mfrow = c(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example2_intro",
   "metadata": {},
   "source": [
    "## Example 2: Local Ancestry Inference\n",
    "\n",
    "Local ancestry inference (LAI) identifies which ancestral population contributed each genomic segment in admixed individuals. For example, African Americans have chromosomes that are mosaics of African and European ancestry. HMMs are ideal for this problem because:\n",
    "\n",
    "- **Hidden states**: Ancestry at each locus (e.g., African, European)\n",
    "- **Observations**: Genotypes at SNP markers\n",
    "- **Sequential structure**: Neighboring SNPs tend to have the same ancestry due to linkage (recombination is rare)\n",
    "\n",
    "This example is inspired by ELAI (Efficient Local Ancestry Inference), which uses a two-layer HMM. We'll implement a simplified version to demonstrate the core concepts.\n",
    "\n",
    "**Key insight**: The transition probabilities in the HMM are related to the recombination rate and the number of generations since admixture. More generations → more recombination → more switches between ancestries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example2_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm(list=ls())\n",
    "set.seed(456)\n",
    "\n",
    "# Simulate admixed individuals with two ancestral populations\n",
    "# Population 1 (e.g., European), Population 2 (e.g., African)\n",
    "\n",
    "n_individuals <- 10\n",
    "n_snps <- 1000\n",
    "n_pops <- 2\n",
    "\n",
    "# Allele frequencies in ancestral populations\n",
    "# Population 1: frequencies centered around 0.3\n",
    "# Population 2: frequencies centered around 0.7\n",
    "# Some SNPs have similar frequencies (uninformative)\n",
    "# Some SNPs have very different frequencies (ancestry-informative markers)\n",
    "\n",
    "freq_pop1 <- runif(n_snps, 0.2, 0.4)\n",
    "freq_pop2 <- runif(n_snps, 0.6, 0.8)\n",
    "\n",
    "# Make some SNPs uninformative (similar frequencies in both populations)\n",
    "uninformative <- sample(1:n_snps, size = n_snps * 0.3)  # 30% uninformative\n",
    "freq_pop2[uninformative] <- freq_pop1[uninformative] + runif(length(uninformative), -0.1, 0.1)\n",
    "freq_pop2[freq_pop2 < 0] <- 0.05\n",
    "freq_pop2[freq_pop2 > 1] <- 0.95\n",
    "\n",
    "# Store frequencies in matrix\n",
    "freq_matrix <- rbind(freq_pop1, freq_pop2)\n",
    "rownames(freq_matrix) <- c(\"Pop1\", \"Pop2\")\n",
    "\n",
    "cat(\"Ancestral Population Allele Frequencies:\\n\")\n",
    "cat(\"First 10 SNPs:\\n\")\n",
    "print(round(freq_matrix[, 1:10], 3))\n",
    "\n",
    "# Calculate informativeness for each SNP\n",
    "delta <- abs(freq_pop1 - freq_pop2)\n",
    "cat(\"\\nAncestry-informative markers (delta > 0.3):\", sum(delta > 0.3), \"\\n\")\n",
    "cat(\"Uninformative markers (delta < 0.1):\", sum(delta < 0.1), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example2_simulate",
   "metadata": {},
   "source": [
    "### Simulate Admixed Genomes\n",
    "\n",
    "We'll simulate individuals with ~60% ancestry from Population 1 and ~40% from Population 2. The ancestry switches along the chromosome according to recombination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example2_sim_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HMM parameters for ancestry inference\n",
    "# Assume 5 generations since admixture, genetic distance ~1 Morgan\n",
    "generations <- 5\n",
    "genetic_length <- 1  # Morgan\n",
    "\n",
    "# Expected number of recombination events = generations * genetic_length\n",
    "expected_switches <- generations * genetic_length\n",
    "\n",
    "# Transition probability between SNPs\n",
    "# Approximate: prob_switch = expected_switches / n_snps\n",
    "prob_switch <- expected_switches / n_snps\n",
    "prob_stay <- 1 - prob_switch\n",
    "\n",
    "# Initial ancestry proportions (global ancestry)\n",
    "pi_anc <- c(0.6, 0.4)  # 60% Pop1, 40% Pop2\n",
    "\n",
    "# Transition matrix (simplified - assumes symmetric switching)\n",
    "A_anc <- matrix(c(\n",
    "  prob_stay, prob_switch,\n",
    "  prob_switch, prob_stay\n",
    "), nrow = 2, byrow = TRUE)\n",
    "\n",
    "cat(\"\\nLocal Ancestry HMM Parameters:\\n\")\n",
    "cat(\"Generations since admixture:\", generations, \"\\n\")\n",
    "cat(\"Expected ancestry switches:\", expected_switches, \"\\n\")\n",
    "cat(\"Transition probability per SNP:\", round(prob_switch, 4), \"\\n\")\n",
    "cat(\"\\nTransition matrix:\\n\")\n",
    "print(round(A_anc, 4))\n",
    "\n",
    "# Simulate admixed genomes\n",
    "simulate_admixed_genome <- function(n_snps, pi, A, freq_matrix) {\n",
    "  # Simulate ancestry for each haplotype (2 per individual)\n",
    "  ancestry_hap1 <- integer(n_snps)\n",
    "  ancestry_hap2 <- integer(n_snps)\n",
    "  \n",
    "  # Haplotype 1\n",
    "  ancestry_hap1[1] <- sample(1:2, 1, prob = pi)\n",
    "  for (i in 2:n_snps) {\n",
    "    ancestry_hap1[i] <- sample(1:2, 1, prob = A[ancestry_hap1[i-1], ])\n",
    "  }\n",
    "  \n",
    "  # Haplotype 2 (independent)\n",
    "  ancestry_hap2[1] <- sample(1:2, 1, prob = pi)\n",
    "  for (i in 2:n_snps) {\n",
    "    ancestry_hap2[i] <- sample(1:2, 1, prob = A[ancestry_hap2[i-1], ])\n",
    "  }\n",
    "  \n",
    "  # Generate genotypes based on ancestry\n",
    "  genotypes <- integer(n_snps)\n",
    "  for (i in 1:n_snps) {\n",
    "    # Allele from haplotype 1\n",
    "    allele1 <- rbinom(1, 1, freq_matrix[ancestry_hap1[i], i])\n",
    "    # Allele from haplotype 2\n",
    "    allele2 <- rbinom(1, 1, freq_matrix[ancestry_hap2[i], i])\n",
    "    genotypes[i] <- allele1 + allele2\n",
    "  }\n",
    "  \n",
    "  return(list(genotypes = genotypes, \n",
    "              ancestry_hap1 = ancestry_hap1,\n",
    "              ancestry_hap2 = ancestry_hap2))\n",
    "}\n",
    "\n",
    "# Simulate multiple individuals\n",
    "sim_data_list <- lapply(1:n_individuals, function(i) {\n",
    "  simulate_admixed_genome(n_snps, pi_anc, A_anc, freq_matrix)\n",
    "})\n",
    "\n",
    "# Extract genotype matrix\n",
    "genotype_matrix <- sapply(sim_data_list, function(x) x$genotypes)\n",
    "genotype_matrix <- t(genotype_matrix)  # individuals x SNPs\n",
    "\n",
    "cat(\"\\nSimulated genotype matrix:\\n\")\n",
    "cat(\"Dimensions:\", dim(genotype_matrix), \"(individuals x SNPs)\\n\")\n",
    "\n",
    "# Show ancestry for first individual\n",
    "true_anc_hap1 <- sim_data_list[[1]]$ancestry_hap1\n",
    "true_anc_hap2 <- sim_data_list[[1]]$ancestry_hap2\n",
    "\n",
    "cat(\"\\nIndividual 1 ancestry summary:\\n\")\n",
    "cat(\"Haplotype 1: Pop1 =\", round(100*mean(true_anc_hap1 == 1), 1), \"%, Pop2 =\", \n",
    "    round(100*mean(true_anc_hap1 == 2), 1), \"%\\n\")\n",
    "cat(\"Haplotype 2: Pop1 =\", round(100*mean(true_anc_hap2 == 1), 1), \"%, Pop2 =\", \n",
    "    round(100*mean(true_anc_hap2 == 2), 1), \"%\\n\")\n",
    "cat(\"Ancestry switches (Hap1):\", sum(diff(true_anc_hap1) != 0), \"\\n\")\n",
    "cat(\"Ancestry switches (Hap2):\", sum(diff(true_anc_hap2) != 0), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example2_visualize_true",
   "metadata": {},
   "source": [
    "### Visualize True Ancestry\n",
    "\n",
    "Let's visualize the true local ancestry for the first individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example2_plot_true",
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow = c(2, 1), mar = c(3, 4, 2, 1))\n",
    "\n",
    "# Plot ancestry for both haplotypes\n",
    "plot(1:n_snps, true_anc_hap1, type = \"s\", lwd = 2, col = \"darkblue\",\n",
    "     xlab = \"\", ylab = \"Ancestry\", ylim = c(0.5, 2.5),\n",
    "     main = \"Individual 1: True Local Ancestry (Haplotype 1)\",\n",
    "     yaxt = \"n\")\n",
    "axis(2, at = 1:2, labels = c(\"Pop1\", \"Pop2\"))\n",
    "\n",
    "plot(1:n_snps, true_anc_hap2, type = \"s\", lwd = 2, col = \"darkred\",\n",
    "     xlab = \"SNP Position\", ylab = \"Ancestry\", ylim = c(0.5, 2.5),\n",
    "     main = \"Individual 1: True Local Ancestry (Haplotype 2)\",\n",
    "     yaxt = \"n\")\n",
    "axis(2, at = 1:2, labels = c(\"Pop1\", \"Pop2\"))\n",
    "\n",
    "par(mfrow = c(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example2_inference",
   "metadata": {},
   "source": [
    "### Infer Local Ancestry Using HMM\n",
    "\n",
    "Now we'll use the Viterbi algorithm to infer the ancestry at each locus. The emission probabilities are based on how likely each genotype is under each ancestry state.\n",
    "\n",
    "**Emission probability calculation**: For a diploid genotype $g \\in \\{0, 1, 2\\}$ at a SNP with allele frequencies $p_1$ (Pop1) and $p_2$ (Pop2), if the average ancestry is population $k$, the expected frequency is approximately $p_k$. Under Hardy-Weinberg equilibrium:\n",
    "\n",
    "$$P(g \\mid \\text{ancestry} = k) = \\binom{2}{g} p_k^g (1-p_k)^{2-g}$$\n",
    "\n",
    "This is a simplification; more sophisticated methods model haplotype-level ancestry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example2_inference_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute emission probability for ancestry inference\n",
    "# P(genotype | ancestry)\n",
    "compute_emission_prob <- function(genotype, freq_pop1, freq_pop2) {\n",
    "  # For each ancestry state, compute P(genotype | frequency)\n",
    "  # Using binomial probability under HWE\n",
    "  \n",
    "  g <- genotype\n",
    "  \n",
    "  # Pop1\n",
    "  p1 <- freq_pop1\n",
    "  prob_pop1 <- dbinom(g, 2, p1)\n",
    "  \n",
    "  # Pop2\n",
    "  p2 <- freq_pop2\n",
    "  prob_pop2 <- dbinom(g, 2, p2)\n",
    "  \n",
    "  return(c(prob_pop1, prob_pop2))\n",
    "}\n",
    "\n",
    "# Viterbi for local ancestry inference\n",
    "viterbi_ancestry <- function(genotypes, freq_pop1, freq_pop2, pi, A) {\n",
    "  n_snps <- length(genotypes)\n",
    "  n_states <- 2\n",
    "  \n",
    "  # Initialize\n",
    "  log_delta <- matrix(-Inf, nrow = n_snps, ncol = n_states)\n",
    "  psi <- matrix(0, nrow = n_snps, ncol = n_states)\n",
    "  \n",
    "  # Emission probabilities for first SNP\n",
    "  emit1 <- compute_emission_prob(genotypes[1], freq_pop1[1], freq_pop2[1])\n",
    "  log_delta[1, ] <- log(pi) + log(emit1 + 1e-10)  # Add small value to avoid log(0)\n",
    "  \n",
    "  # Recursion\n",
    "  for (i in 2:n_snps) {\n",
    "    emit_i <- compute_emission_prob(genotypes[i], freq_pop1[i], freq_pop2[i])\n",
    "    \n",
    "    for (j in 1:n_states) {\n",
    "      temp <- log_delta[i-1, ] + log(A[, j] + 1e-10)\n",
    "      psi[i, j] <- which.max(temp)\n",
    "      log_delta[i, j] <- max(temp) + log(emit_i[j] + 1e-10)\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # Backtracking\n",
    "  best_path <- integer(n_snps)\n",
    "  best_path[n_snps] <- which.max(log_delta[n_snps, ])\n",
    "  \n",
    "  for (i in (n_snps-1):1) {\n",
    "    best_path[i] <- psi[i+1, best_path[i+1]]\n",
    "  }\n",
    "  \n",
    "  return(best_path)\n",
    "}\n",
    "\n",
    "# Infer ancestry for first individual\n",
    "ind1_genotypes <- genotype_matrix[1, ]\n",
    "inferred_ancestry <- viterbi_ancestry(ind1_genotypes, freq_pop1, freq_pop2, pi_anc, A_anc)\n",
    "\n",
    "# Note: We're inferring average ancestry (not haplotype-specific)\n",
    "# True average ancestry\n",
    "true_avg_ancestry <- round((true_anc_hap1 + true_anc_hap2) / 2)\n",
    "true_avg_ancestry[true_avg_ancestry == 2] <- 2  # If both haplotypes are Pop2\n",
    "true_avg_ancestry[true_avg_ancestry == 1] <- 1  # If average is Pop1\n",
    "\n",
    "# For comparison, let's use a simpler rule: if both haplotypes are same, that's the ancestry\n",
    "# Otherwise, call it as mixed (but for this simple model, we'll just compare to one haplotype)\n",
    "\n",
    "cat(\"\\nLocal Ancestry Inference Results:\\n\")\n",
    "cat(\"Inferred global ancestry proportions:\\n\")\n",
    "cat(\"Pop1:\", round(100*mean(inferred_ancestry == 1), 1), \"%\\n\")\n",
    "cat(\"Pop2:\", round(100*mean(inferred_ancestry == 2), 1), \"%\\n\")\n",
    "\n",
    "# Compare with true (using haplotype 1 as reference)\n",
    "accuracy_anc <- sum(inferred_ancestry == true_anc_hap1) / n_snps\n",
    "cat(\"\\nAccuracy (vs Hap1):\", round(100*accuracy_anc, 2), \"%\\n\")\n",
    "\n",
    "# Inferred ancestry switches\n",
    "cat(\"Inferred ancestry switches:\", sum(diff(inferred_ancestry) != 0), \"\\n\")\n",
    "cat(\"True ancestry switches (Hap1):\", sum(diff(true_anc_hap1) != 0), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example2_visualize_inferred",
   "metadata": {},
   "source": [
    "### Compare Inferred vs True Ancestry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example2_plot_compare",
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow = c(3, 1), mar = c(3, 4, 2, 1))\n",
    "\n",
    "# Plot 1: True ancestry (Hap1)\n",
    "plot(1:n_snps, true_anc_hap1, type = \"s\", lwd = 2, col = \"darkgreen\",\n",
    "     xlab = \"\", ylab = \"Ancestry\", ylim = c(0.5, 2.5),\n",
    "     main = \"True Local Ancestry (Haplotype 1)\",\n",
    "     yaxt = \"n\")\n",
    "axis(2, at = 1:2, labels = c(\"Pop1\", \"Pop2\"))\n",
    "\n",
    "# Plot 2: Inferred ancestry\n",
    "plot(1:n_snps, inferred_ancestry, type = \"s\", lwd = 2, col = \"steelblue\",\n",
    "     xlab = \"\", ylab = \"Ancestry\", ylim = c(0.5, 2.5),\n",
    "     main = \"Inferred Local Ancestry (HMM)\",\n",
    "     yaxt = \"n\")\n",
    "axis(2, at = 1:2, labels = c(\"Pop1\", \"Pop2\"))\n",
    "\n",
    "# Plot 3: Ancestry informativeness (delta)\n",
    "plot(1:n_snps, delta, type = \"h\", col = \"coral\", lwd = 1,\n",
    "     xlab = \"SNP Position\", ylab = \"Freq Diff\",\n",
    "     main = \"Ancestry Informativeness (|p1 - p2|)\")\n",
    "abline(h = 0.3, lty = 2, col = \"red\", lwd = 2)\n",
    "text(n_snps*0.8, 0.35, \"Highly informative\", col = \"red\")\n",
    "\n",
    "par(mfrow = c(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example2_summary",
   "metadata": {},
   "source": [
    "### Summary: Local Ancestry Inference\n",
    "\n",
    "The HMM successfully identifies genomic segments from different ancestral populations. Key observations:\n",
    "\n",
    "1. **Accuracy depends on informativeness**: Regions with highly ancestry-informative markers (large frequency differences) are easier to infer correctly.\n",
    "\n",
    "2. **Sequential structure helps**: The HMM leverages linkage disequilibrium - neighboring SNPs tend to have the same ancestry, which improves accuracy even at uninformative markers.\n",
    "\n",
    "3. **Transition probabilities encode recombination**: The rate of ancestry switching in the HMM reflects the number of generations since admixture and the recombination rate.\n",
    "\n",
    "4. **Real methods are more sophisticated**: Tools like ELAI use two-layer HMMs and model haplotype-level ancestry explicitly, achieving higher accuracy than this simplified example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example3_intro",
   "metadata": {},
   "source": [
    "## Example 3: Genotype Imputation\n",
    "\n",
    "Genotype imputation infers missing genotypes at untyped markers using a reference panel of haplotypes. This is crucial in GWAS because:\n",
    "- Genotyping arrays only assay ~500K-1M SNPs, but the genome has millions of variants\n",
    "- Different studies use different arrays, making meta-analysis difficult\n",
    "- Imputation allows us to test association at variants not on the array\n",
    "\n",
    "**The HMM framework**:\n",
    "- **Hidden states**: Reference panel haplotypes (each haplotype is a state)\n",
    "- **Observations**: Genotypes at typed markers\n",
    "- **Key idea**: Each study sample is a mosaic of reference haplotypes due to shared ancestry\n",
    "\n",
    "We'll implement a simplified version inspired by the Li-Stephens model used in tools like IMPUTE and Minimac."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example3_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm(list=ls())\n",
    "set.seed(789)\n",
    "\n",
    "# Simulate a reference panel of haplotypes\n",
    "n_ref_haps <- 50    # Number of reference haplotypes\n",
    "n_markers <- 500    # Total number of markers in the region\n",
    "n_typed <- 100      # Number of typed markers (20%)\n",
    "\n",
    "# Generate reference haplotypes\n",
    "# We'll create structured haplotypes with some shared segments (LD)\n",
    "# Start with founders and simulate recombination\n",
    "\n",
    "n_founders <- 10\n",
    "freq <- runif(n_markers, 0.1, 0.9)  # Allele frequencies\n",
    "\n",
    "# Create founder haplotypes\n",
    "founder_haps <- matrix(rbinom(n_founders * n_markers, 1, rep(freq, each = n_founders)),\n",
    "                       nrow = n_founders, ncol = n_markers)\n",
    "\n",
    "# Generate reference haplotypes as mosaics of founders\n",
    "# This creates LD structure\n",
    "ref_haplotypes <- matrix(0, nrow = n_ref_haps, ncol = n_markers)\n",
    "\n",
    "for (i in 1:n_ref_haps) {\n",
    "  # Start with a random founder\n",
    "  current_founder <- sample(1:n_founders, 1)\n",
    "  \n",
    "  for (j in 1:n_markers) {\n",
    "    # Small probability of switching to another founder (recombination)\n",
    "    if (runif(1) < 0.02) {\n",
    "      current_founder <- sample(1:n_founders, 1)\n",
    "    }\n",
    "    ref_haplotypes[i, j] <- founder_haps[current_founder, j]\n",
    "  }\n",
    "}\n",
    "\n",
    "cat(\"Reference Panel:\\n\")\n",
    "cat(\"Number of haplotypes:\", n_ref_haps, \"\\n\")\n",
    "cat(\"Number of markers:\", n_markers, \"\\n\")\n",
    "cat(\"Reference panel dimensions:\", dim(ref_haplotypes), \"\\n\")\n",
    "\n",
    "# Select which markers are typed vs untyped\n",
    "typed_indices <- sort(sample(1:n_markers, n_typed))\n",
    "untyped_indices <- setdiff(1:n_markers, typed_indices)\n",
    "\n",
    "cat(\"\\nTyped markers:\", n_typed, \"\\n\")\n",
    "cat(\"Untyped markers:\", length(untyped_indices), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example3_simulate",
   "metadata": {},
   "source": [
    "### Create Study Sample\n",
    "\n",
    "Now we'll create a study sample that is related to the reference panel (shares haplotype segments). We'll then \"mask\" genotypes at untyped markers and try to impute them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example3_study",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a study sample haplotype as a mosaic of reference haplotypes\n",
    "# This simulates the fact that the study sample shares recent ancestry with the reference\n",
    "\n",
    "true_study_haplotype <- integer(n_markers)\n",
    "true_state_path <- integer(n_markers)  # Which reference haplotype at each position\n",
    "\n",
    "# Start with a random reference haplotype\n",
    "current_ref <- sample(1:n_ref_haps, 1)\n",
    "true_state_path[1] <- current_ref\n",
    "\n",
    "for (j in 1:n_markers) {\n",
    "  # Small probability of switching to another reference haplotype\n",
    "  if (j > 1 && runif(1) < 0.01) {\n",
    "    current_ref <- sample(1:n_ref_haps, 1)\n",
    "  }\n",
    "  true_state_path[j] <- current_ref\n",
    "  true_study_haplotype[j] <- ref_haplotypes[current_ref, j]\n",
    "}\n",
    "\n",
    "# Add some genotyping errors at typed positions\n",
    "observed_study_haplotype <- true_study_haplotype\n",
    "error_rate <- 0.005\n",
    "errors <- rbinom(n_typed, 1, error_rate)\n",
    "error_positions <- typed_indices[errors == 1]\n",
    "observed_study_haplotype[error_positions] <- 1 - observed_study_haplotype[error_positions]\n",
    "\n",
    "# Mask untyped positions (set to NA)\n",
    "observed_study_haplotype_masked <- observed_study_haplotype\n",
    "observed_study_haplotype_masked[untyped_indices] <- NA\n",
    "\n",
    "cat(\"\\nStudy Sample:\\n\")\n",
    "cat(\"True number of reference switches:\", sum(diff(true_state_path) != 0), \"\\n\")\n",
    "cat(\"Genotyping errors introduced:\", length(error_positions), \"\\n\")\n",
    "cat(\"Observed alleles (typed only):\", sum(!is.na(observed_study_haplotype_masked)), \"\\n\")\n",
    "cat(\"Missing alleles (untyped):\", sum(is.na(observed_study_haplotype_masked)), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example3_hmm",
   "metadata": {},
   "source": [
    "### HMM for Imputation\n",
    "\n",
    "The Li-Stephens HMM treats each reference haplotype as a hidden state. The key components:\n",
    "\n",
    "**Transition probabilities**: Probability of switching from one reference haplotype to another\n",
    "$$P(\\text{switch}) \\approx \\exp(-\\rho d)$$\n",
    "where $\\rho$ is recombination rate and $d$ is genetic distance.\n",
    "\n",
    "**Emission probabilities**: At typed markers, how well does the reference haplotype match the observed genotype?\n",
    "$$P(\\text{obs} | \\text{ref}) = \\begin{cases} 1 - \\epsilon & \\text{if match} \\\\ \\epsilon & \\text{if mismatch} \\end{cases}$$\n",
    "where $\\epsilon$ is the genotyping error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example3_impute",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified imputation using HMM forward-backward algorithm\n",
    "# We'll compute posterior probability of each allele at untyped markers\n",
    "\n",
    "# HMM parameters\n",
    "theta <- 0.01  # Switching rate between reference haplotypes\n",
    "epsilon <- 0.01  # Genotyping error rate\n",
    "\n",
    "# For simplicity, uniform initial distribution\n",
    "pi_imp <- rep(1/n_ref_haps, n_ref_haps)\n",
    "\n",
    "# Transition matrix: mostly stay in same state\n",
    "# P(stay in same ref haplotype) = 1 - theta\n",
    "# P(switch to any other) = theta / (n_ref_haps - 1)\n",
    "prob_stay <- 1 - theta\n",
    "prob_switch <- theta / (n_ref_haps - 1)\n",
    "\n",
    "A_imp <- matrix(prob_switch, nrow = n_ref_haps, ncol = n_ref_haps)\n",
    "diag(A_imp) <- prob_stay\n",
    "\n",
    "# Forward algorithm for imputation\n",
    "forward_imputation <- function(observed_hap, ref_haplotypes, pi, A, epsilon, typed_indices) {\n",
    "  n_markers <- length(observed_hap)\n",
    "  n_states <- nrow(ref_haplotypes)\n",
    "  \n",
    "  # Forward variables\n",
    "  log_alpha <- matrix(-Inf, nrow = n_markers, ncol = n_states)\n",
    "  \n",
    "  # Only compute at typed positions to save time\n",
    "  # At untyped positions, just propagate forward\n",
    "  \n",
    "  # Initialization at first typed marker\n",
    "  first_typed <- typed_indices[1]\n",
    "  obs_allele <- observed_hap[first_typed]\n",
    "  \n",
    "  for (k in 1:n_states) {\n",
    "    ref_allele <- ref_haplotypes[k, first_typed]\n",
    "    match_prob <- ifelse(obs_allele == ref_allele, 1 - epsilon, epsilon)\n",
    "    log_alpha[first_typed, k] <- log(pi[k]) + log(match_prob)\n",
    "  }\n",
    "  \n",
    "  # Forward recursion (only at typed markers for efficiency)\n",
    "  for (i in 2:length(typed_indices)) {\n",
    "    curr_pos <- typed_indices[i]\n",
    "    prev_pos <- typed_indices[i-1]\n",
    "    \n",
    "    # Distance-based transition (simplified)\n",
    "    distance <- curr_pos - prev_pos\n",
    "    A_dist <- A\n",
    "    \n",
    "    obs_allele <- observed_hap[curr_pos]\n",
    "    \n",
    "    for (k in 1:n_states) {\n",
    "      ref_allele <- ref_haplotypes[k, curr_pos]\n",
    "      match_prob <- ifelse(obs_allele == ref_allele, 1 - epsilon, epsilon)\n",
    "      \n",
    "      # Sum over previous states\n",
    "      log_alpha[curr_pos, k] <- log(sum(exp(log_alpha[prev_pos, ] + log(A_dist[, k])))) + \n",
    "                                 log(match_prob)\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  return(log_alpha)\n",
    "}\n",
    "\n",
    "cat(\"\\nRunning forward algorithm for imputation...\\n\")\n",
    "cat(\"This may take a moment...\\n\")\n",
    "\n",
    "log_alpha <- forward_imputation(observed_study_haplotype_masked, ref_haplotypes, \n",
    "                                pi_imp, A_imp, epsilon, typed_indices)\n",
    "\n",
    "cat(\"Forward algorithm completed.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example3_dosage",
   "metadata": {},
   "source": [
    "### Compute Imputation Dosages\n",
    "\n",
    "At each untyped marker, we compute the posterior probability that the allele is 1 (alternative allele). This is called the \"dosage\" and can be used directly in association testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example3_dosage_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each untyped marker, compute P(allele = 1 | observed data)\n",
    "# This requires knowing which reference haplotype we're likely copying\n",
    "\n",
    "imputed_dosages <- rep(NA, n_markers)\n",
    "imputed_dosages[typed_indices] <- observed_study_haplotype_masked[typed_indices]\n",
    "\n",
    "# For each untyped marker\n",
    "for (pos in untyped_indices) {\n",
    "  # Find the nearest typed markers before and after\n",
    "  typed_before <- typed_indices[typed_indices < pos]\n",
    "  typed_after <- typed_indices[typed_indices > pos]\n",
    "  \n",
    "  if (length(typed_before) == 0 || length(typed_after) == 0) {\n",
    "    # At edges, use population frequency\n",
    "    imputed_dosages[pos] <- mean(ref_haplotypes[, pos])\n",
    "    next\n",
    "  }\n",
    "  \n",
    "  nearest_before <- max(typed_before)\n",
    "  nearest_after <- min(typed_after)\n",
    "  \n",
    "  # Get posterior distribution over states at flanking positions\n",
    "  alpha_before <- exp(log_alpha[nearest_before, ])\n",
    "  alpha_before <- alpha_before / sum(alpha_before)\n",
    "  \n",
    "  # Weight each reference haplotype by its posterior probability\n",
    "  # and take weighted average of alleles\n",
    "  weighted_alleles <- sum(alpha_before * ref_haplotypes[, pos])\n",
    "  imputed_dosages[pos] <- weighted_alleles\n",
    "}\n",
    "\n",
    "# Convert dosages to hard calls (0 or 1) for accuracy assessment\n",
    "imputed_calls <- round(imputed_dosages)\n",
    "\n",
    "# Evaluate imputation accuracy at untyped markers\n",
    "accuracy_untyped <- sum(imputed_calls[untyped_indices] == true_study_haplotype[untyped_indices]) / \n",
    "                    length(untyped_indices)\n",
    "\n",
    "cat(\"\\nImputation Results:\\n\")\n",
    "cat(\"Accuracy at untyped markers:\", round(100*accuracy_untyped, 2), \"%\\n\")\n",
    "\n",
    "# Show some examples\n",
    "cat(\"\\nFirst 10 untyped markers:\\n\")\n",
    "example_untyped <- untyped_indices[1:10]\n",
    "results_df <- data.frame(\n",
    "  Position = example_untyped,\n",
    "  True_Allele = true_study_haplotype[example_untyped],\n",
    "  Imputed_Dosage = round(imputed_dosages[example_untyped], 3),\n",
    "  Imputed_Call = imputed_calls[example_untyped],\n",
    "  Correct = imputed_calls[example_untyped] == true_study_haplotype[example_untyped]\n",
    ")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example3_visualize",
   "metadata": {},
   "source": [
    "### Visualize Imputation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example3_plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on a smaller region for visualization\n",
    "region_start <- 1\n",
    "region_end <- 200\n",
    "region <- region_start:region_end\n",
    "\n",
    "typed_in_region <- typed_indices[typed_indices >= region_start & typed_indices <= region_end]\n",
    "untyped_in_region <- untyped_indices[untyped_indices >= region_start & untyped_indices <= region_end]\n",
    "\n",
    "par(mfrow = c(2, 1), mar = c(4, 4, 3, 1))\n",
    "\n",
    "# Plot 1: True vs Imputed alleles\n",
    "plot(region, true_study_haplotype[region], type = \"n\",\n",
    "     xlab = \"Marker Position\", ylab = \"Allele\",\n",
    "     main = \"Genotype Imputation: True vs Imputed\",\n",
    "     ylim = c(-0.2, 1.2))\n",
    "\n",
    "# True alleles\n",
    "points(region, true_study_haplotype[region], pch = 16, col = \"black\", cex = 0.8)\n",
    "\n",
    "# Typed positions (observed)\n",
    "points(typed_in_region, observed_study_haplotype[typed_in_region], \n",
    "       pch = 1, col = \"blue\", cex = 1.5, lwd = 2)\n",
    "\n",
    "# Imputed positions\n",
    "points(untyped_in_region, imputed_calls[untyped_in_region], \n",
    "       pch = 4, col = \"red\", cex = 1)\n",
    "\n",
    "# Highlight imputation errors\n",
    "errors_in_region <- untyped_in_region[imputed_calls[untyped_in_region] != \n",
    "                                       true_study_haplotype[untyped_in_region]]\n",
    "if (length(errors_in_region) > 0) {\n",
    "  points(errors_in_region, imputed_calls[errors_in_region], \n",
    "         pch = 4, col = \"orange\", cex = 2, lwd = 3)\n",
    "}\n",
    "\n",
    "legend(\"topleft\", \n",
    "       legend = c(\"True\", \"Typed (observed)\", \"Imputed correct\", \"Imputed error\"),\n",
    "       pch = c(16, 1, 4, 4),\n",
    "       col = c(\"black\", \"blue\", \"red\", \"orange\"),\n",
    "       pt.cex = c(0.8, 1.5, 1, 2),\n",
    "       pt.lwd = c(1, 2, 1, 3))\n",
    "\n",
    "# Plot 2: Imputation dosages (uncertainty)\n",
    "plot(region, imputed_dosages[region], type = \"n\",\n",
    "     xlab = \"Marker Position\", ylab = \"Allele Dosage\",\n",
    "     main = \"Imputation Dosages (Posterior Probability of Alt Allele)\",\n",
    "     ylim = c(-0.1, 1.1))\n",
    "\n",
    "# Show dosages at untyped positions\n",
    "points(untyped_in_region, imputed_dosages[untyped_in_region],\n",
    "       pch = 16, col = \"purple\", cex = 0.8)\n",
    "\n",
    "# Add reference lines\n",
    "abline(h = 0.5, lty = 2, col = \"gray\")\n",
    "text(region_end - 20, 0.55, \"Uncertain (dosage = 0.5)\", col = \"gray\")\n",
    "\n",
    "# Highlight confident vs uncertain imputation\n",
    "confident <- untyped_in_region[abs(imputed_dosages[untyped_in_region] - 0.5) > 0.3]\n",
    "uncertain <- untyped_in_region[abs(imputed_dosages[untyped_in_region] - 0.5) <= 0.3]\n",
    "\n",
    "if (length(confident) > 0) {\n",
    "  points(confident, imputed_dosages[confident], pch = 16, col = \"darkgreen\", cex = 1.2)\n",
    "}\n",
    "if (length(uncertain) > 0) {\n",
    "  points(uncertain, imputed_dosages[uncertain], pch = 16, col = \"orange\", cex = 1.2)\n",
    "}\n",
    "\n",
    "par(mfrow = c(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example3_summary",
   "metadata": {},
   "source": [
    "### Summary: Genotype Imputation\n",
    "\n",
    "The HMM-based imputation method successfully recovers most untyped genotypes by leveraging:\n",
    "\n",
    "1. **Shared haplotype segments**: Study samples are mosaics of reference haplotypes due to shared ancestry. The HMM identifies which reference haplotypes the study sample is copying.\n",
    "\n",
    "2. **Linkage disequilibrium**: Typed markers provide information about nearby untyped markers because alleles are correlated.\n",
    "\n",
    "3. **Transition probabilities**: The switching rate between reference haplotypes is based on recombination rate and time to common ancestor.\n",
    "\n",
    "4. **Dosages vs hard calls**: Rather than making hard 0/1 calls, imputation produces dosages (posterior probabilities) that quantify uncertainty. This is important for:\n",
    "   - Rare variants (often uncertain)\n",
    "   - Regions with weak LD\n",
    "   - Association testing (dosages can be used directly)\n",
    "\n",
    "**Real imputation tools** (IMPUTE2, Minimac, Beagle) use more sophisticated models:\n",
    "- Pre-phase haplotypes using more complex HMMs\n",
    "- Use forward-backward algorithm for full posterior\n",
    "- Handle large reference panels (10,000s of haplotypes) efficiently\n",
    "- Model haplotype clusters to reduce computational complexity\n",
    "- Achieve >98% accuracy for common variants with large reference panels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Hidden Markov Models are fundamental tools in statistical genetics that elegantly handle sequential data with hidden structure. The three examples demonstrate how HMMs:\n",
    "\n",
    "1. **Model sequential dependencies**: The Markov property captures the fact that neighboring genomic positions are correlated (due to LD, limited recombination)\n",
    "\n",
    "2. **Handle uncertainty**: Emission probabilities account for noise (genotyping errors, measurement uncertainty)\n",
    "\n",
    "3. **Enable efficient inference**: Dynamic programming algorithms (forward, Viterbi, Baum-Welch) make exact inference tractable even for long sequences\n",
    "\n",
    "**Key algorithms recap**:\n",
    "- **Forward**: Compute $P(\\text{observations})$\n",
    "- **Viterbi**: Find most likely state sequence\n",
    "- **Forward-Backward**: Compute posterior state probabilities\n",
    "- **Baum-Welch**: Learn HMM parameters\n",
    "\n",
    "HMMs remain workhorses in modern genomics, underlying tools for imputation (IMPUTE2, Minimac), local ancestry (RFMix, ELAI), copy number variation (HMMcopy), and chromatin state annotation (ChromHMM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
