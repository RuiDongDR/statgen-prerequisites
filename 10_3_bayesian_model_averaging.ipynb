{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b83af83b-505c-4cfc-a1a9-7d1d3d583ee9",
   "metadata": {},
   "source": [
    "## Bayesian model averaging\n",
    "\n",
    "# Intuition\n",
    "\n",
    "**FIGURE PLACEHOLDER:** ![Bayesian model averaging](image_placeholder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b4eeab-8946-4c60-a76a-b9cda53cd052",
   "metadata": {},
   "source": [
    "# Notation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf773a9-c031-4639-9b63-9ce12822f596",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Averaging\n",
    "\n",
    "**Model Averaging** is a technique used in statistical modeling that combines predictions from multiple models to improve accuracy and robustness. Instead of selecting a single best model, model averaging considers the contribution of several models, weighted by their plausibility, and uses them to generate a more reliable prediction.\n",
    "\n",
    "The basic idea behind model averaging is that different models may capture different aspects of the underlying data or process, and combining them can lead to better overall performance, especially when some models perform better in some regions of the data and worse in others.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3efd7f1-4c0f-47e5-ab90-6abc9cbef87d",
   "metadata": {},
   "source": [
    "\n",
    "### Theoretical Background\n",
    "\n",
    "Let’s assume we have a set of models $M_1, M_2, \\dots, M_K$ and we want to predict a value for a new observation $y^*$ based on the models. For each model $M_k$, we calculate a prediction, denoted as $\\hat{y}^*_k$. \n",
    "\n",
    "The **model-averaged prediction** is typically given by the weighted sum of the predictions from each model:\n",
    "\n",
    "$$\n",
    "\\hat{y}^*_{\\text{avg}} = \\sum_{k=1}^{K} w_k \\hat{y}^*_k\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $w_k$ is the weight associated with model $M_k$, which reflects how likely or good the model is at describing the data.\n",
    "- $\\hat{y}^*_k$ is the prediction made by model $M_k$ for the new data point.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8252a27-8b2d-44fd-8657-76a40e07e273",
   "metadata": {},
   "source": [
    "### Weights in Model Averaging\n",
    "\n",
    "The weights $w_k$ can be assigned based on various criteria:\n",
    "1. **Bayesian Model Averaging (BMA)**: In the Bayesian framework, the weights correspond to the posterior model probabilities, i.e., the probability of each model given the data:\n",
    "\n",
    "   $$ \n",
    "   w_k = P(M_k | D) \n",
    "   $$\n",
    "\n",
    "   Where $P(M_k | D)$ is the posterior probability of model $M_k$ given the observed data $D$.\n",
    "\n",
    "2. **Akaike Information Criterion (AIC) or Bayesian Information Criterion (BIC)**: In a frequentist context, the weights are often computed based on the relative likelihood of each model, using information criteria like AIC or BIC. The models with lower AIC/BIC values are considered to be more likely and receive higher weights.\n",
    "\n",
    "   $$ \n",
    "   w_k = \\frac{e^{-\\frac{1}{2} \\Delta \\text{AIC}_k}}{\\sum_{j=1}^K e^{-\\frac{1}{2} \\Delta \\text{AIC}_j}} \n",
    "   $$\n",
    "\n",
    "   Where $\\Delta \\text{AIC}_k = \\text{AIC}_k - \\min(\\text{AIC})$, and $\\text{AIC}_k$ is the AIC of model $k$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03ac6af-c3b1-47fd-8592-cd9246471a4b",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "### Why Model Averaging Works\n",
    "\n",
    "1. **Reduced Risk of Overfitting**: By averaging over multiple models, we avoid overfitting to any one model. Even if one model fits the training data well but fails to generalize, other models can provide complementary information, reducing the overall risk of overfitting.\n",
    "  \n",
    "2. **Improved Accuracy**: If models make different types of errors, combining their predictions can reduce the variance and bias, leading to more accurate predictions.\n",
    "\n",
    "3. **Incorporating Model Uncertainty**: In cases where model uncertainty is high, model averaging incorporates this uncertainty by using multiple models and averaging their predictions, rather than relying on a single model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a200e1c3-4870-4370-8741-eda6809eb029",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65bf3cb-c17e-41a5-a0c2-72871b4b2361",
   "metadata": {},
   "source": [
    "## Model Averaging for Height Prediction\n",
    "\n",
    "Let’s take the example of predicting height in our genetic model. Assume we have two models:\n",
    "\n",
    "- $M_1$ is a model that assumes no genetic effect on height.\n",
    "- $M_2$ is a model that includes a genetic effect on height.\n",
    "\n",
    "We calculate the predictions $\\hat{y}^*_{M_1}$ and $\\hat{y}^*_{M_2}$ for a new individual based on the genotypic data. We can then average these predictions, weighted by the relative credibility of each model, to obtain a model-averaged prediction.\n",
    "\n",
    "### Steps for Model Averaging\n",
    "\n",
    "1. **Fit multiple models**: Fit several candidate models to the data. Each model may differ in terms of assumptions or included predictors (e.g., one model may include genetic effects, and another may exclude them).\n",
    "  \n",
    "2. **Calculate model weights**: Assign weights to the models based on their performance (AIC, BIC, posterior probability, etc.).\n",
    "\n",
    "3. **Average predictions**: For a new data point, use the weighted sum of the model predictions to generate the final prediction.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Model averaging helps combine the strengths of multiple models, offering more reliable and robust predictions, especially in situations where there is uncertainty about which model is the best. In practice, this technique is particularly useful when dealing with complex or noisy data, where no single model is likely to capture the entire underlying process perfectly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ed4b5e-e9b5-4437-879c-257d80a18317",
   "metadata": {},
   "source": [
    "**EXAMPLE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c03431a-30ff-4bd8-a0fa-90712e2a859d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c48d288-0385-44fc-8230-253e6d52217e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.2"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
